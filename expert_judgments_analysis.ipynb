{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1747aef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import gmean\n",
    "import openpyxl\n",
    "\n",
    "def load_pairwise_matrices(file_path):\n",
    "    \"\"\"\n",
    "    Load pairwise comparison matrices from Excel file with multiple expert sheets\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the Excel file\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (criteria_names, expert_matrices_dict)\n",
    "    \"\"\"\n",
    "    # Load the Excel file\n",
    "    wb = openpyxl.load_workbook(file_path)\n",
    "    \n",
    "    # Get all sheet names (should be Expert_1, Expert_2, etc.)\n",
    "    expert_sheets = [sheet for sheet in wb.sheetnames if sheet.startswith('Expert_')]\n",
    "    \n",
    "    # Read the first sheet to get criteria names\n",
    "    first_sheet = wb[expert_sheets[0]]\n",
    "    \n",
    "    # Extract criteria names from the first row (starting from column B)\n",
    "    criteria = []\n",
    "    for cell in first_sheet[1][1:]:  # Skip the first cell (A1)\n",
    "        if cell.value is not None:\n",
    "            criteria.append(cell.value)\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    n_criteria = len(criteria)\n",
    "    expert_matrices = {}\n",
    "    \n",
    "    # Read matrices from each expert sheet\n",
    "    for sheet_name in expert_sheets:\n",
    "        sheet = wb[sheet_name]\n",
    "        matrix = []\n",
    "        \n",
    "        # Extract the matrix values (starting from row 2, column B)\n",
    "        for i in range(2, 2 + n_criteria):  # Rows 2 to n_criteria+1\n",
    "            row = []\n",
    "            for j in range(2, 2 + n_criteria):  # Columns B to n_criteria+1\n",
    "                cell_value = sheet.cell(row=i, column=j).value\n",
    "                if cell_value is not None:\n",
    "                    row.append(float(cell_value))\n",
    "                else:\n",
    "                    row.append(1.0)  # Default diagonal value\n",
    "            matrix.append(row)\n",
    "        \n",
    "        expert_matrices[sheet_name] = np.array(matrix)\n",
    "    \n",
    "    wb.close()\n",
    "    return criteria, expert_matrices\n",
    "\n",
    "def calculate_ahp_weights(matrix):\n",
    "    \"\"\"\n",
    "    Calculate AHP weights using the geometric mean method (exactly as in your code)\n",
    "    \n",
    "    Args:\n",
    "        matrix (numpy.ndarray): Pairwise comparison matrix\n",
    "        \n",
    "    Returns:\n",
    "        numpy.ndarray: Normalized weights\n",
    "    \"\"\"\n",
    "    # Calculate geometric mean of each row\n",
    "    n = matrix.shape[0]\n",
    "    geometric_means = []\n",
    "    \n",
    "    for i in range(n):\n",
    "        # Calculate geometric mean of row i\n",
    "        row_product = 1.0\n",
    "        for j in range(n):\n",
    "            row_product *= matrix[i, j]\n",
    "        geometric_means.append(row_product ** (1.0 / n))\n",
    "    \n",
    "    # Normalize to get weights\n",
    "    geometric_means = np.array(geometric_means)\n",
    "    weights = geometric_means / np.sum(geometric_means)\n",
    "    \n",
    "    return weights\n",
    "\n",
    "def calculate_consistency_ratio(matrix, weights):\n",
    "    \"\"\"\n",
    "    Calculate the consistency ratio exactly as in your code\n",
    "    \n",
    "    Args:\n",
    "        matrix (numpy.ndarray): Pairwise comparison matrix\n",
    "        weights (numpy.ndarray): Priority weights\n",
    "        \n",
    "    Returns:\n",
    "        float: Consistency ratio\n",
    "    \"\"\"\n",
    "    n = matrix.shape[0]\n",
    "    \n",
    "    # Calculate lambda_max\n",
    "    weighted_sum = np.dot(matrix, weights)\n",
    "    lambda_max = np.sum(weighted_sum / weights) / n\n",
    "    \n",
    "    # Calculate consistency index\n",
    "    ci = (lambda_max - n) / (n - 1)\n",
    "    \n",
    "    # Random consistency index for different matrix sizes (your exact values)\n",
    "    ri_values = {1: 0, 2: 0, 3: 0.52, 4: 0.89, 5: 1.11, 6: 1.25, 7: 1.35, 8: 1.40, \n",
    "                 9: 1.45, 10: 1.49, 11: 1.52, 12: 1.54, 13: 1.56, 14: 1.58, 15: 1.59}\n",
    "    \n",
    "    ri = ri_values.get(n, 1.59)  # Use 1.59 for matrices larger than 15x15\n",
    "    \n",
    "    # Calculate consistency ratio\n",
    "    cr = ci / ri if ri > 0 else 0\n",
    "    \n",
    "    return cr\n",
    "\n",
    "def kendall_w(rankings):\n",
    "    \"\"\"Calculate Kendall's coefficient of concordance\"\"\"\n",
    "    rankings = np.array(rankings)\n",
    "    m, n = rankings.shape  # m judges, n items\n",
    "    \n",
    "    # Convert weights to rankings (1 = highest weight)\n",
    "    ranked_data = np.zeros_like(rankings)\n",
    "    for i in range(m):\n",
    "        ranked_data[i] = n + 1 - np.argsort(np.argsort(rankings[i]))\n",
    "    \n",
    "    rank_sums = np.sum(ranked_data, axis=0)\n",
    "    mean_rank_sum = np.mean(rank_sums)\n",
    "    s = np.sum((rank_sums - mean_rank_sum)**2)\n",
    "    \n",
    "    w = 12 * s / (m**2 * (n**3 - n))\n",
    "    return w\n",
    "\n",
    "def calculate_expert_consensus(file_path):\n",
    "    \"\"\"\n",
    "    Calculate expert-derived criteria weights and consensus rankings\n",
    "    Matches your exact calculation methodology\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the Excel file with expert matrices\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: Results table with weights, rankings, and statistics\n",
    "    \"\"\"\n",
    "    # Load the matrices\n",
    "    criteria, expert_matrices = load_pairwise_matrices(file_path)\n",
    "    \n",
    "    # Calculate weights for each expert\n",
    "    expert_weights = {}\n",
    "    expert_consistency = {}\n",
    "    \n",
    "    for expert_name, matrix in expert_matrices.items():\n",
    "        weights = calculate_ahp_weights(matrix)\n",
    "        cr = calculate_consistency_ratio(matrix, weights)\n",
    "        \n",
    "        expert_weights[expert_name] = weights\n",
    "        expert_consistency[expert_name] = cr\n",
    "    \n",
    "    # Create DataFrame with all expert weights\n",
    "    weights_df = pd.DataFrame(expert_weights, index=criteria)\n",
    "    \n",
    "    # Calculate geometric mean across experts for each criterion (your method)\n",
    "    geometric_mean_weights = []\n",
    "    for i in range(len(criteria)):\n",
    "        criterion_weights = [expert_weights[expert][i] for expert in expert_weights.keys()]\n",
    "        geom_mean = gmean(criterion_weights)\n",
    "        geometric_mean_weights.append(geom_mean)\n",
    "    \n",
    "    # Normalize geometric mean weights\n",
    "    geometric_mean_weights = np.array(geometric_mean_weights)\n",
    "    geometric_mean_weights = geometric_mean_weights / np.sum(geometric_mean_weights)\n",
    "    \n",
    "    # Calculate standard deviation and coefficient of variation (your method)\n",
    "    std_devs = []\n",
    "    cvs = []\n",
    "    \n",
    "    for i in range(len(criteria)):\n",
    "        criterion_weights = [expert_weights[expert][i] for expert in expert_weights.keys()]\n",
    "        std_dev = np.std(criterion_weights, ddof=1)  # Sample standard deviation\n",
    "        cv = std_dev / np.mean(criterion_weights)  # CV based on arithmetic mean\n",
    "        \n",
    "        std_devs.append(std_dev)\n",
    "        cvs.append(cv)\n",
    "    \n",
    "    # Calculate Kendall's W for inter-expert agreement\n",
    "    weights_array = np.array([expert_weights[expert] for expert in expert_weights.keys()])\n",
    "    kendall_w_value = kendall_w(weights_array)\n",
    "    \n",
    "    # Create results DataFrame\n",
    "    results_df = pd.DataFrame({\n",
    "        'Criterion': criteria,\n",
    "        'Geometric Mean Weight': geometric_mean_weights,\n",
    "        'Std Dev': std_devs,\n",
    "        'CV': cvs\n",
    "    })\n",
    "    \n",
    "    # Sort by geometric mean weight (descending) and add rank\n",
    "    results_df = results_df.sort_values('Geometric Mean Weight', ascending=False)\n",
    "    results_df['Rank'] = range(1, len(results_df) + 1)\n",
    "    \n",
    "    # Reorder columns to match Table 2 format\n",
    "    results_df = results_df[['Rank', 'Criterion', 'Geometric Mean Weight', 'Std Dev', 'CV']]\n",
    "    \n",
    "    # Print expert panel characteristics and consistency performance\n",
    "    n_experts = len(expert_matrices)\n",
    "    consistency_ratios = list(expert_consistency.values())\n",
    "    mean_cr = np.mean(consistency_ratios)\n",
    "    std_cr = np.std(consistency_ratios, ddof=1)\n",
    "    acceptable_consistency = sum(1 for cr in consistency_ratios if cr < 0.1)\n",
    "    \n",
    "    print(\"Expert Panel Characteristics and Consistency Performance\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Panel Size: {n_experts} experts\")\n",
    "    print(f\"Mean Consistency Ratio (CR): {mean_cr:.4f} (SD = {std_cr:.4f})\")\n",
    "    print(f\"Acceptable Consistency (CR < 10%): {acceptable_consistency}/{n_experts} ({100*acceptable_consistency/n_experts:.0f}%)\")\n",
    "    print(f\"Kendall's W (Inter-expert agreement): {kendall_w_value:.3f}\")\n",
    "    \n",
    "    # Print individual consistency ratios\n",
    "    print(f\"\\nConsistency Ratios by Expert:\")\n",
    "    for expert, cr in expert_consistency.items():\n",
    "        print(f\"{expert}: {cr:.4f}\")\n",
    "    \n",
    "    return results_df, mean_cr, std_cr, kendall_w_value\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Load and analyze the data\n",
    "    file_path = \"data/simple_matrices.xlsx\"  # Update with your file path\n",
    "    \n",
    "    try:\n",
    "        results, mean_cr, std_cr, kendall_w_value = calculate_expert_consensus(file_path)\n",
    "        \n",
    "        # Display the final results table (matching your format)\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"Table 2. Expert-Derived Criteria Weights and Consensus Rankings\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # Format the results for display exactly as you did\n",
    "        print(f\"{'Rank':<6} {'Criterion':<35} {'Geometric Mean Weight':<20} {'Std Dev':<12} {'CV':<8}\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        for _, row in results.iterrows():\n",
    "            print(f\"{row['Rank']:<6} {row['Criterion']:<35} {row['Geometric Mean Weight']:<20.6f} \"\n",
    "                  f\"{row['Std Dev']:<12.6f} {row['CV']:<8.4f}\")\n",
    "        \n",
    "        # Save results to CSV\n",
    "        results.to_csv(\"expert_consensus_results.csv\", index=False)\n",
    "        print(f\"\\nResults saved to 'expert_consensus_results.csv'\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        print(\"Please make sure the Excel file exists and has the correct format.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new-geo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
